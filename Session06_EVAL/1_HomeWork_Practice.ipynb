{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69917869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"my_api_key: [{my_api_key[-4:]},....,[{my_api_key[:4]}]\")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages = [{\"role\": \"system\", \n",
    "                 \"content\": \"Hello! How are you today?\"},\n",
    "                {\"role\": \"user\", \n",
    "                 \"content\":\n",
    "                   [{\"type\":\"text\",\"text\":\"Extract Key field\"},\n",
    "                    {\"type\":\"image_url\",\"image_url\":{\"url\":\"https://example.com/sample-image1.jpg\"}}    \n",
    "                    ]}])\n",
    "\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#client = OpenAI(api_key=my_api_key)\n",
    "print(f\"my api key is:[{my_api_key[:4]}...{my_api_key[-4:]}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = [1, 2, 3, 4, 5]\n",
    "num_mean = sum(number_list) / len(number_list)\n",
    "print(f\"The mean of the list is: {num_mean}\")\n",
    "\n",
    "num_median = sorted(number_list)[len(number_list) // 2]\n",
    "print(f\"The median of the list is: {num_median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp ={'Name': 'John Doe', 'Age': 30, 'Department': 'Sales', 'Salary': 100000}\n",
    "print(\"emp Name:\",{emp[\"Name\"]})\n",
    "print(f\"emp name :[{emp[\"Name\"]}]\")\n",
    "\n",
    "#Increase salary by 10%\n",
    "emp['Salary'] = emp['Salary']*1.1\n",
    "print(f\"Updated emp salary :[{emp['Salary']}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac829c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\" Artificial Intelligence (AI) is a branch of computer science that focuses on creating \n",
    "intelligent machines capable of performing tasks that typically require human intelligence. These tasks include learning, reasoning, \n",
    "problem-solving, understanding natural language, and perception.\"\"\"\n",
    "\n",
    "#List of words with repeated\n",
    "words = paragraph.split()\n",
    "word_count = {}\n",
    "for word in words:\n",
    "    word = word.lower().strip('.,()')\n",
    "    if word in word_count:\n",
    "        word_count[word] += 1\n",
    "    else:\n",
    "        word_count[word] = 1\n",
    "\n",
    "for word, count in word_count.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a script to read and write JSON files using the json module.\n",
    "\n",
    "import json\n",
    "data = {\n",
    "    \"employees\": [\n",
    "        {\"name\": \"John Doe\", \"age\": 30, \"department\": \"Sales\"},\n",
    "        {\"name\": \"Jane Smith\", \"age\": 25, \"department\": \"Marketing\"},\n",
    "        {\"name\": \"Mike Johnson\", \"age\": 35, \"department\": \"IT\"}\n",
    "    ]\n",
    "}\n",
    "# Write JSON data to a file\n",
    "with open('employees.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)    \n",
    "# Read JSON data from a file\n",
    "with open('employees.json', 'r') as json_file:\n",
    "    loaded_data = json.load(json_file)\n",
    "    print(loaded_data)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8059189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SentenceTransformer, encode two sentences and compute cosine similarity.\n",
    "\n",
    "sentence1 = \"Artificial Intelligence is the future.\"\n",
    "sentence2 = \"AI will shape the world ahead.\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emb1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "emb2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "cosine_score = util.pytorch_cos_sim(emb1, emb2)\n",
    "print(f\"Cosine Similarity between the sentences: {cosine_score.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a15d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pandas, create a DataFrame from a dictionary and perform basic data analysis.\n",
    "\n",
    "employee_dict = {\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Mike Johnson'],\n",
    "    'Age': [30, 25, 35],\n",
    "    'Department': ['Sales', 'Marketing', 'IT'],\n",
    "    'Salary': [100000, 90000, 110000]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(employee_dict)\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nBasic Data Analysis:\")\n",
    "print(f\"Average Age: {df['Age'].mean()}\")\n",
    "print(f\"Total Salary: {df['Salary'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python function that takes a list of numbers and returns the mean, median, and mode.\n",
    "numbers = [1, 2, 2, 3, 4]\n",
    "from statistics import mean, median, mode\n",
    "def calculate_statistics(num_list):\n",
    "    return {\n",
    "        'mean': mean(num_list),\n",
    "        'median': median(num_list),\n",
    "        'mode': mode(num_list)\n",
    "    }       \n",
    "stats = calculate_statistics(numbers)\n",
    "print(f\"Statistics: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that creates embeddings for each sentence in a text file and saves them as a csv .\n",
    "\n",
    "def create_embeddings_to_csv(input_file, output_file):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import pandas as pd\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        sentences = file.readlines()\n",
    "\n",
    "    embeddings = [model.encode(sentence.strip()) for sentence in sentences]\n",
    "\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Embeddings saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to data/embeddings.json\n"
     ]
    }
   ],
   "source": [
    "input_file = 'data/EmbedExample.txt'\n",
    "output_file = 'data/embeddings.csv'\n",
    "create_embeddings_to_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb18e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that creates embeddings for each sentence in a text file and saves them as a json .\n",
    "def create_embeddings_to_json(input_file, output_file):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import pandas as pd\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        sentences = file.readlines()\n",
    "\n",
    "    embeddings = [model.encode(sentence.strip()) for sentence in sentences]\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    df.to_json(output_file, index=False)\n",
    "    print(f\"Embeddings saved to {output_file}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b1160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarat\\Downloads\\GENAI\\Training\\SLGenerativeAI11126\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to data/assignment_embd.json\n"
     ]
    }
   ],
   "source": [
    "input_file = 'data/assignment.json'\n",
    "output_file = 'data/assignment_embd.json'\n",
    "create_embeddings_to_json(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
